# We taught a robot how to eat apples.

Ok, we did not, it does not chew nor digest the apple.  But we taught it how to see one, reach for it and aovid obstacles in between.  Does that sond cool? Certainly. But, how did we do it?  How could it be useful? Well, stay with us to the end... 



## How we did it

Small introduction, Franka Panda, etc. etc. 



#### Module 1  - The eyes

 Sevim. Please emphasize that CoCo is the dataset with objects of the daily living!!

#### Module 2  - The reaching 

Making a robot reach for a detected object might sound like a trivial problems. In robotics it is not. Helping 



```Markdown
$$ y = y(x,t) &= A e^{i\theta} $$




```

#### Module 3  - The sensing



Claudia



## Wait, but what for?

The non-technical reader might be most impressed by our approach and achievements. But, he or she may wonder, why was it worth the effort? Is this another brick towards a Terminator machine programmed to kill Sarah Connor? 

We think the opposite. We believe a robot that can interact with its environment might be very well used as a device that helps humans. Think about it: picture a robot arm in the house of a person with disabilities, either motor impairments or an elderly adult.  If this arm is in the capacity of interacting with the environment, detecting objects of the daily living and interacting with them, it would be well suited to become a personal helper of the individual, thus helping them gain a certain degree of independance. 

This vision on assistive robotics is, of course, not new. But our belief is that  an holistic approach (i.e., a system in which machine learning, computer vision, classical robotics, human-robot interfaces and control theory are present and interact) is the way to go.  We hope that our progress with this Franka robot, who we nicknamed Sarah Connor*, helps laying a brick towards _that_ nicer future. 

/* No pun intended.



